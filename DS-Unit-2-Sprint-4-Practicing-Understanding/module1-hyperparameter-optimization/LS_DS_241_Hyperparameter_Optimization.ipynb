{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O67uhlT4MExK"
   },
   "source": [
    "_Lambda School Data Science — Practicing & Understanding Predictive Modeling_\n",
    "\n",
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VE4rfZd4NUGA"
   },
   "source": [
    "Today we'll use this process:\n",
    "\n",
    "## \"A universal workflow of machine learning\"\n",
    "\n",
    "_Excerpt from Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning_\n",
    " \n",
    "**1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
    "\n",
    "**2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
    "\n",
    "**3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
    "\n",
    "**4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
    "\n",
    "**5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
    "\n",
    "**6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
    "\n",
    "**Iterate on feature engineering: add new features, or remove features that don’t seem to be informative.** \n",
    "\n",
    "Once you’ve developed a satisfactory model configuration, you can **train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3kt6bzEcOIaa"
   },
   "source": [
    "## 1. Define the problem at hand and the data on which you'll train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "di16k7vpRg67"
   },
   "source": [
    "We'll apply the workflow to a [project from _Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic) by Jake VanderPlas:\n",
    "\n",
    "> **Predicting Bicycle Traffic**\n",
    "\n",
    "> As an example, let's take a look at whether we can predict the number of bicycle trips across Seattle's Fremont Bridge based on weather, season, and other factors.\n",
    "\n",
    "> We will join the bike data with another dataset, and try to determine the extent to which weather and seasonal factors—temperature, precipitation, and daylight hours—affect the volume of bicycle traffic through this corridor. Fortunately, the NOAA makes available their daily [weather station data](http://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND) (I used station ID USW00024233) and we can easily use Pandas to join the two data sources.\n",
    "\n",
    "> Let's start by loading the two datasets, indexing by date:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19dpb_d0R1A6"
   },
   "source": [
    "So this is a regression problem, not a classification problem. We'll define the target, choose an evaluation metric, and choose models that are appropriate for regression problems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "os1zruXQ30KM"
   },
   "source": [
    "### Download data\n",
    "\n",
    "Commands for use in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XVu-HSeMDtV"
   },
   "outputs": [],
   "source": [
    "# !curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sih_7mTzMdfr"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GYm74kD34OQ"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackprinter\n",
    "stackprinter.set_excepthook(style='lightbg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BfQ7gE28MNdF"
   },
   "outputs": [],
   "source": [
    "# Modified from cells 15, 16, and 20, at\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Download and join data into a dataframe\n",
    "def load(): \n",
    "    fremont_bridge = '~/U2S4-Practicing-Understanding/module1-hyperparameter-optimization/FremontBridge.csv'\n",
    "    \n",
    "    bicycle_weather = '~/U2S4-Practicing-Understanding/module1-hyperparameter-optimization/BicycleWeather.csv'\n",
    "\n",
    "    counts = pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
    "                         infer_datetime_format=True)\n",
    "\n",
    "    weather = pd.read_csv(bicycle_weather, index_col='DATE', parse_dates=True, \n",
    "                          infer_datetime_format=True)\n",
    "\n",
    "    daily = counts.resample('d').sum()\n",
    "    daily['Total'] = daily.sum(axis=1)\n",
    "    daily = daily[['Total']] # remove other columns\n",
    "\n",
    "    weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
    "    daily = daily.join(weather[weather_columns], how='inner')\n",
    "    \n",
    "    # Make a feature for yesterday's total\n",
    "    daily['Total_yesterday'] = daily.Total.shift(1)\n",
    "    daily = daily.drop(index=daily.index[0])\n",
    "    \n",
    "    return daily\n",
    "\n",
    "daily = load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVB3g4704An5"
   },
   "source": [
    "### First fast look at the data\n",
    "- What's the shape?\n",
    "- What's the date range?\n",
    "- What's the target and the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily shape: (1063, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1063 entries, 2012-10-04 to 2015-09-01\n",
      "Data columns (total 8 columns):\n",
      "Total              1063 non-null float64\n",
      "PRCP               1063 non-null int64\n",
      "SNOW               1063 non-null int64\n",
      "SNWD               1063 non-null int64\n",
      "TMAX               1063 non-null int64\n",
      "TMIN               1063 non-null int64\n",
      "AWND               1063 non-null int64\n",
      "Total_yesterday    1063 non-null float64\n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 74.7 KB\n"
     ]
    }
   ],
   "source": [
    "print('daily shape:', daily.shape)\n",
    "daily.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-04</th>\n",
       "      <td>3475.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>83</td>\n",
       "      <td>65</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-05</th>\n",
       "      <td>3148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>89</td>\n",
       "      <td>57</td>\n",
       "      <td>3475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-06</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>78</td>\n",
       "      <td>51</td>\n",
       "      <td>3148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>2142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-08</th>\n",
       "      <td>3537.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>2142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
       "2012-10-04  3475.0     0     0     0   189    83    65           3521.0\n",
       "2012-10-05  3148.0     0     0     0   217    89    57           3475.0\n",
       "2012-10-06  2006.0     0     0     0   239    78    51           3148.0\n",
       "2012-10-07  2142.0     0     0     0   239    78    13           2006.0\n",
       "2012-10-08  3537.0     0     0     0   211    78    19           2142.0"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-28</th>\n",
       "      <td>2653.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>156</td>\n",
       "      <td>26</td>\n",
       "      <td>4336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-29</th>\n",
       "      <td>699.0</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>133</td>\n",
       "      <td>58</td>\n",
       "      <td>2653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-30</th>\n",
       "      <td>1213.0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>47</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-31</th>\n",
       "      <td>2823.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>161</td>\n",
       "      <td>58</td>\n",
       "      <td>1213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01</th>\n",
       "      <td>2876.0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>139</td>\n",
       "      <td>-9999</td>\n",
       "      <td>2823.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
       "2015-08-28  2653.0     5     0     0   233   156    26           4336.0\n",
       "2015-08-29   699.0   325     0     0   222   133    58           2653.0\n",
       "2015-08-30  1213.0   102     0     0   200   128    47            699.0\n",
       "2015-08-31  2823.0     0     0     0   189   161    58           1213.0\n",
       "2015-09-01  2876.0    58     0     0   194   139 -9999           2823.0"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgMvCsaWJR7Q"
   },
   "source": [
    "Target\n",
    "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
    "\n",
    "Features\n",
    "- Date (index) : from 2012-10-04 to 2015-09-01\n",
    "- Total_yesterday : Total trips yesterday\n",
    "- PRCP : Precipitation (1/10 mm)\n",
    "- SNOW : Snowfall (1/10 mm)\n",
    "- SNWD : Snow depth (1/10 mm)\n",
    "- TMAX : Maximum temperature (1/10 Celsius)\n",
    "- TMIN : Minimum temperature (1/10 Celsius)\n",
    "- AWND : Average daily wind speed (1/10 meters per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lenL-przSYCo"
   },
   "source": [
    "## 2. Choose how you’ll measure success on your problem.\n",
    "\n",
    "Which metrics will you monitor on your validation data?\n",
    "\n",
    "This is a regression problem, so we need to choose a regression [metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
    "\n",
    "\n",
    "\n",
    "I'll choose mean absolute error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TqbomapSyRP"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRHrB3rsS5hF"
   },
   "source": [
    "## 3. Determine your evaluation protocol \n",
    "\n",
    "We're doing model selection, hyperparameter optimization, and performance estimation. So generally we have two ideal [options](https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg) to choose from:\n",
    "\n",
    "- 3-way holdout method (train/validation/test split)\n",
    "- Cross-validation with independent test set\n",
    "\n",
    "I'll choose cross-validation with independent test set. Scikit-learn makes cross-validation convenient for us!\n",
    "\n",
    "Specifically, I will use random shuffled cross validation to train and validate, but I will hold out an **\"out-of-time\" test set**, from the last 100 days of data.\n",
    "\n",
    "Out-of-time test/validation sets can actually be more difficult/realistic as evaluation data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3xo6HgbPMFm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((963, 8), (100, 8))"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = daily[:-100] # everything except last 100 days\n",
    "test = daily[-100:] # last 100 days\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of X_train, y_train, X_test, y_test:  (963, 7) (963,) (100, 7) (100,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(columns='Total')\n",
    "y_train = train['Total']\n",
    "\n",
    "X_test = test.drop(columns='Total')\n",
    "y_test = test['Total']\n",
    "\n",
    "print('Shapes of X_train, y_train, X_test, y_test: ', X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vH6IsORQTvTU"
   },
   "source": [
    "## 4. Develop a first model that does better than a basic baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJBs2nQkj7oB"
   },
   "source": [
    "### Look at the target's distribution and descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5peakv9Zs71"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     963.000000\n",
       "mean     2534.329180\n",
       "std      1224.065027\n",
       "min        98.000000\n",
       "25%      1755.000000\n",
       "50%      2381.000000\n",
       "75%      3317.500000\n",
       "max      6088.000000\n",
       "Name: Total, dtype: float64"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEjxxgV9kExY"
   },
   "source": [
    "### Basic baseline 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GepKdQjYcEP"
   },
   "source": [
    "We could always predict mean, always predict median, etc.. The units of MAE is in the units of the target: number of cyclists.\n",
    "\n",
    "Link to MAE explanation: https://www.statisticshowto.datasciencecentral.com/absolute-error/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GepKdQjYcEP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971.9376947040498"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [y_train.median()] * len(y_train)\n",
    "mean_absolute_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tN2I_F3FkIHb"
   },
   "source": [
    "### Basic baseline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-04</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>83</td>\n",
       "      <td>65</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-05</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>89</td>\n",
       "      <td>57</td>\n",
       "      <td>3475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>78</td>\n",
       "      <td>51</td>\n",
       "      <td>3148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>2142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
       "2012-10-04     0     0     0   189    83    65           3521.0\n",
       "2012-10-05     0     0     0   217    89    57           3475.0\n",
       "2012-10-06     0     0     0   239    78    51           3148.0\n",
       "2012-10-07     0     0     0   239    78    13           2006.0\n",
       "2012-10-08     0     0     0   211    78    19           2142.0"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZW8bhZFtTunV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708.061266874351"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_train['Total_yesterday']    # Sometimes called \"Lag of 1\" prediction\n",
    "mean_absolute_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ggf3VpxwkJ0T"
   },
   "source": [
    "### First model that does better than a basic baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfaqL1Ezer2-"
   },
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OeBtU68skfW-"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OeBtU68skfW-"
   },
   "source": [
    "`cross_validate()` can also return scores per fold and estimator per fold. \n",
    "\n",
    "Most of the sklearn metrics are trying to MAXIMIZE the score, so metrics starting w/ `neg_` means that the lower score is better where 0 is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OeBtU68skfW-"
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(LinearRegression(), X_train, y_train,\n",
    "                        scoring='neg_mean_absolute_error', cv=3,\n",
    "                        return_train_score=True, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01097083, 0.01296258, 0.0109694 ]),\n",
       " 'score_time': array([0.00498629, 0.00498891, 0.00299287]),\n",
       " 'estimator': (LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "           normalize=False),\n",
       "  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "           normalize=False),\n",
       "  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "           normalize=False)),\n",
       " 'test_score': array([-555.18627454, -651.12651327, -615.96579978]),\n",
       " 'train_score': array([-619.50920623, -583.42770209, -589.3413007 ])}"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a dictionary, but converts to DataFrame nicely\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-555.186275</td>\n",
       "      <td>-619.509206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-651.126513</td>\n",
       "      <td>-583.427702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-615.965800</td>\n",
       "      <td>-589.341301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time                                          estimator  \\\n",
       "0  0.010971    0.004986  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "1  0.012963    0.004989  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "2  0.010969    0.002993  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "\n",
       "   test_score  train_score  \n",
       "0 -555.186275  -619.509206  \n",
       "1 -651.126513  -583.427702  \n",
       "2 -615.965800  -589.341301  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607.4261958631805"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python syntax: prepend a subtraction operator to\n",
    "# flip the sign / multiply by -1\n",
    "-scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from coss-validation fold #0\n",
      "Intercept:  566.7766337283692\n",
      "PRCP               -3.525103\n",
      "SNOW               -0.082029\n",
      "SNWD              -12.045027\n",
      "TMAX                9.475238\n",
      "TMIN               -4.607775\n",
      "AWND               -2.745191\n",
      "Total_yesterday     0.417360 \n",
      "\n",
      "Model from coss-validation fold #1\n",
      "Intercept:  671.9064515706045\n",
      "PRCP               -2.772253\n",
      "SNOW               -0.000995\n",
      "SNWD               20.800688\n",
      "TMAX                8.804948\n",
      "TMIN               -3.741386\n",
      "AWND               -6.108300\n",
      "Total_yesterday     0.405074 \n",
      "\n",
      "Model from coss-validation fold #2\n",
      "Intercept:  465.84525362296336\n",
      "PRCP               -2.876196\n",
      "SNOW               -0.016432\n",
      "SNWD               -8.809696\n",
      "TMAX               10.419441\n",
      "TMIN               -5.862868\n",
      "AWND               -2.398991\n",
      "Total_yesterday     0.423493 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(scores['estimator']):\n",
    "    coefficients = model.coef_\n",
    "    intercept = model.intercept_\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    print(f'Model from coss-validation fold #{i}')\n",
    "    print('Intercept: ', intercept)\n",
    "    print(pd.Series(coefficients, feature_names).to_string(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fg1YI4X8n9nI"
   },
   "source": [
    "## 5. Develop a model that overfits. \n",
    "\n",
    "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —Chollet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lodd6UPOoy89"
   },
   "source": [
    "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
    "\n",
    "Diagram Source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xj82P0VdwYlh"
   },
   "source": [
    "### Random Forest?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_yYXpk99C4cM"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_yYXpk99C4cM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.740008</td>\n",
       "      <td>0.112251</td>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>-559.582368</td>\n",
       "      <td>-244.363754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298212</td>\n",
       "      <td>0.109167</td>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>-643.953333</td>\n",
       "      <td>-224.569221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.367982</td>\n",
       "      <td>0.111306</td>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>-642.810530</td>\n",
       "      <td>-223.789922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time                                          estimator  \\\n",
       "0  3.740008    0.112251  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "1  0.298212    0.109167  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "2  0.367982    0.111306  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "\n",
       "   test_score  train_score  \n",
       "0 -559.582368  -244.363754  \n",
       "1 -643.953333  -224.569221  \n",
       "2 -642.810530  -223.789922  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, max_depth=None, n_jobs=-1)\n",
    "\n",
    "scores = cross_validate(model, X_train, y_train, scoring='neg_mean_absolute_error',\n",
    "                        cv=3, return_train_score=True, return_estimator=True)\n",
    "\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615.4487435098649"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'test_score' is more akin to validation score\n",
    "-scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ryO1hVKr-6f"
   },
   "source": [
    "### Validation Curve\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
    "\n",
    "> Validation curve. Determine training and test scores for varying parameter values. This is similar to grid search with one parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apKk4vKiwgtM"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VNX9//HXx4CyCAKCikQ2FVlCwg4WCaKIiHUBRNGvC6hlqVtrpa4VpFpXqtWKVNRSLSgBXOoC9YdVAQUk7CBrWCQssiPIIknO748zWQgTEshyM5n38/GYB5M7dyafXJJ5zz3nnnPMOYeIiES3k4IuQEREgqcwEBERhYGIiCgMREQEhYGIiKAwEBERFAYiIoLCQEREUBiIiAhQLugCCqpmzZqufv36QZchIhJR5s6du905Vyu//SImDOrXr09ycnLQZYiIRBQzW1+Q/dRMJCIiCgMREVEYiIgIEdRnEM7hw4dJTU3l4MGDQZcihVChQgViY2MpX7580KWIRK2IDoPU1FSqVKlC/fr1MbOgy5ET4Jxjx44dpKam0qBBg6DLEYlaEd1MdPDgQU4//XQFQQQzM04//XSd3YkELKLDAFAQlAH6PxQJXsSHgYhIWTVnDjzySMl8L4VBIezevZuRI0ee0HN79OjB7t27j7nP448/ztSpU0/o9UUkcs2fD1dfDe3aweuvw8aNxf89FQaFcKwwSE9PP+ZzP/vsM6pVq3bMfYYPH07Xrl1PuL7ikt/PJiInZvFi6N0bWrWC6dPhySdh7VqoU6f4v3eRhIGZPWBmzsxqhr6ub2YHzGxB6DYqx76tzWyxma02s5ctghuMH3roIVJSUmjRogVDhgzhq6++okuXLtx00000b94cgGuvvZbWrVvTrFkzXn/99azn1q9fn+3bt7Nu3TqaNGnCb37zG5o1a0a3bt04cOAAAP369WPixIlZ+w8dOpRWrVrRvHlzli9fDsC2bdu47LLLaNWqFQMHDqRevXps3779iDrT09Pp168fcXFxNG/enBdffBGA1atX07VrVxISEmjVqhUpKSk45xgyZEjWvuPHjwcI+7P9+9//pl27drRo0YKBAwcqJERO0LJl0LcvJCTA1KkwbBisWwePPgpVqpRMDYW+tNTMzgEuA37I9VCKc65FmKe8BgwAZgGfAd2ByYWt43e/gwULCvsqR2rRAl56Ke/Hn3nmGZYsWcKC0Df+6quv+O6771iyZEnWZZJvvfUWNWrU4MCBA7Rt25bevXtz+umnH/E6q1at4t1332X06NFcf/31TJo0iZtvvvmo71ezZk3mzZvHyJEjeeGFF3jjjTd44oknuOSSS3j44YeZMmXKEYGTacGCBWzcuJElS5YAZDVP/d///R8PPfQQPXv25ODBg2RkZPD++++zYMECFi5cyPbt22nbti2JiYkAR/xsy5YtY/z48XzzzTeUL1+e3/72t4wdO5Zbb731+A+0SJRatQqeeALGjYPKlX3/wP33Q40aJV9LUZwZvAj8EXD57WhmtYGqzrmZzjkHvA1cWwQ1lBrt2rU74nr5l19+mYSEBDp06MCGDRtYtWrVUc9p0KABLVr43GzdujXr1q0L+9q9evU6ap8ZM2bQt29fALp370716tWPel7Dhg1Zs2YN99xzD1OmTKFq1ars3buXjRs30rNnT8AP/KpUqRIzZszgxhtvJCYmhjPPPJPOnTszZ86co362L774grlz59K2bVtatGjBF198wZo1a07giIlEnzVroH9/aNIEPvgAhgzxzUFPPhlMEEAhzwzM7Gpgo3NuYZjWngZmNh/4CXjMOTcdqAOk5tgnNbQtr9cfgD+LoG7duses5Vif4EtS5cqVs+5/9dVXTJ06lZkzZ1KpUiUuvvjisNfTn3LKKVn3Y2JispqJ8tovJiaGtLQ0wA/ayk/16tVZuHAh//3vf3n11VdJSkripTwO2LFeL+fP5pzjtttu4+mnn873+4uIt349PPUU/POfUK4c3HsvPPggnHlm0JUV4MzAzKaa2ZIwt2uAR4HHwzxtM1DXOdcSuB8YZ2ZVgXD9A3m++zjnXnfOtXHOtalVK9/puEtclSpV2Lt3b56P79mzh+rVq1OpUiWWL1/OrFmziryGiy66iKSkJAA+//xzdu3addQ+27dvJyMjg969e/PnP/+ZefPmUbVqVWJjY/nwww8BOHToEPv37ycxMZHx48eTnp7Otm3bmDZtGu3atTvqNS+99FImTpzI1q1bAdi5cyfr1xdoplyRqLNxI9x1F5x/PvzrXzBoEKSkwF//WjqCAApwZuCcC3s5i5k1BxoAmWcFscA8M2vnnNsCHAo9f66ZpQCN8GcCsTleJhbYVKifIECnn346HTt2JC4ujiuuuIIrr7zyiMe7d+/OqFGjiI+P54ILLqBDhw5FXsPQoUO58cYbGT9+PJ07d6Z27dpUydXjtHHjRvr3709GRgZA1qf5d955h4EDB/L4449Tvnx5JkyYQM+ePZk5cyYJCQmYGc899xxnnXVWVod1pqZNm/Lkk0/SrVs3MjIyKF++PK+++ir16tUr8p9RJFJt2QLPPAOjRkF6Otxxh+8UPuecoCsLwzlXJDdgHVAzdL8WEBO63xDYCNQIfT0H6IA/S5gM9CjI67du3drl9v333x+1LdocPHjQHT582Dnn3LfffusSEhICrujE6P9SypKtW537wx+cq1jRuZgY5+64w7m1a4OpBUh2BXiPLa6J6hKB4WaWBqQDg5xzO0OPDQbGABVDYVDoK4mi2Q8//MD1119PRkYGJ598MqNHjw66JJGotWMHvPACvPIKHDgAN98Mf/oTnHde0JXlr8jCwDlXP8f9ScCkPPZLBuKK6vtGu/PPP5/58+cHXYZIVNu927f/v/QS7Nvnxww8/jg0bhx0ZQUX0VNYi4gE6aef4G9/gxEjYM8euO46GDoU4iLw467CQETkOO3bB3//Ozz/POzcCddc4wePJSQEXdmJUxiIiBTQ/v0wciQ8+yxs3w49esDw4dC6ddCVFZ4mqhMRycfBg745qGFDP1q4VSuYORM+/bRsBAEoDErcqaeeCsCmTZu47rrrwu5z8cUXk5ycfMzXeemll9i/f3/W1wWZEltEjs+hQ/5M4Nxz/fxnTZrAtGnw3/9CMQwbCpTCICBnn3121oykJyJ3GBRkSuwgaCZTiUSHD8Po0dCokR853KAB/O9/8OWX0KlT0NUVD4VBITz44INHrGcwbNgwRowYwb59+7j00kuzppv+6KOPjnruunXriAtdcnDgwAH69u1LfHw8N9xwwxFzEw0ePJg2bdrQrFkzhg4dCvjJ7zZt2kSXLl3o0qULkD0lNsBf//pX4uLiiIuLy5qD6FhTZec0YcIE4uLiSEhIyJqtND09nQceeIDmzZsTHx/PK6+8AvjJ6lq2bEnz5s25/fbbOXToUFYtw4cP56KLLmLChAmkpKTQvXt3WrduTadOnY4azSxSWqSlwZgxcMEFMGAA1K4Nn3/u1xYI/amVXQUZmVYabvmOQL7vPuc6dy7a2333HXNk37x581xiYmLW102aNHHr1693hw8fdnv27HHOObdt2zZ37rnnuoyMDOecc5UrV3bOObd27VrXrFkz55xzI0aMcP3793fOObdw4UIXExPj5syZ45xzbseOHc4559LS0lznzp3dwoULnXPO1atXz23bti3re2d+nZyc7OLi4ty+ffvc3r17XdOmTd28efPc2rVrXUxMjJs/f75zzrk+ffq4d95556ifKS4uzqWmpjrnnNu1a5dzzrmRI0e6Xr16ZY103rFjhztw4ICLjY11K1ascM45d8stt7gXX3wxq5Znn3026zUvueQSt3LlSuecc7NmzXJdunQ56vtqBLIEKS3NuXfece6885wD51q3du7TT50L/dlGNAo4AllnBoXQsmVLtm7dyqZNm1i4cCHVq1enbt26OOd45JFHiI+Pp2vXrmzcuJEff/wxz9eZNm1a1voF8fHxxMfHZz2WlJREq1ataNmyJUuXLuX7778/Zk0zZsygZ8+eVK5cmVNPPZVevXoxffp0oGBTZXfs2JF+/foxevTorCaeqVOnMmjQIMqV8xef1ahRgxUrVtCgQQMaNWoEwG233ca0adOyXueGG24AYN++fXz77bf06dMnaxGczZs3H/NnECkpGRkwfrwfF3DLLVCpEnz4oV97uEcPiNylt45f2bm0NKA5rK+77jomTpzIli1bstYVGDt2LNu2bWPu3LmUL1+e+vXrh526OqdwC76tXbuWF154gTlz5lC9enX69euX7+u4Y0xBXZCpskeNGsXs2bP59NNPadGiBQsWLMA5d1R9x/o+kD3ddUZGBtWqVctaAEikNMjI8G/6Q4fCkiXQtClMmAC9esFJUfoROUp/7KLTt29f3nvvPSZOnJh1ddCePXs444wzKF++PF9++WW+UzsnJiYyduxYAJYsWcKiRYsA+Omnn6hcuTKnnXYaP/74I5MnZ0/jlNf02YmJiXz44Yfs37+fn3/+mQ8++IBOx9HjlZKSQvv27Rk+fDg1a9Zkw4YNdOvWjVGjRmWtobBz504aN27MunXrWL16NeBnQO3cufNRr1e1alUaNGjAhAkTAB8iCxcuLHA9IkXJOfj4Y385aO/e8MsvfpWxRYv86OFoDQJQGBRas2bN2Lt3L3Xq1KF27dqAX04yOTmZNm3aMHbsWBrnM0HJ4MGD2bdvH/Hx8Tz33HNZ6wckJCTQsmVLmjVrxu23307Hjh2znjNgwACuuOKKrA7kTK1ataJfv360a9eO9u3bc+edd9KyZcsC/zxDhgyhefPmxMXFkZiYSEJCAnfeeSd169YlPj6ehIQExo0bR4UKFfjnP/9Jnz59aN68OSeddBKDBg0K+5pjx47lzTffJCEhgWbNmoXtUBcpTs7BlCnQvj1cfbWfRuJf/4KlS+HGGyEmJugKg2f5ne6XFm3atHG5r71ftmwZTZo0CagiKUr6v5Ti4Bx88YWfNG7mTKhXz9+/5RYoXz7o6kqGmc11zrXJbz+dGYhImfT113DxxXDZZbBhg19gZuVKuP326AmC46EwEJEy5dtvoWtXHwSrVvm1BVatgoED4eSTg66u9Ir4MIiUZi7Jm/4PpSh89x107w4dO8LixX59gZQUuPtuqFAh6OpKv4gOgwoVKrBjxw69mUQw5xw7duyggv5a5QTNnw9XXeU7h5OT/Yyia9bA738PFSsGXV3kiOhxBrGxsaSmprJt27agS5FCqFChArGxsUGXIRFm0SIYNgw++ACqVYMnn4R774UqVYKuLDJFdBiUL1+eBg0aBF2GiJSg77/3C8kkJUHVqj4Qfvc7OO20oCuLbBEdBiISPVau9CHw7rtQuTI8+ijcfz/UqBF0ZWWDwkBESrU1a/xqYu+84zuChwzxt5o1g66sbFEYiEiptH697wcYMwbKlYP77oMHH4Qzzwy6srJJYSAipUpqKvzlL/DGG37W0EGD4OGH4eyzg66sbFMYiEipsHkzPPMM/OMfflbRO+6ARx6Bc84JurLooDAQkUBt3erHBowc6Zeb7NcPHnsM6tcPurLoojAQkUDs2AHPP++nizh4EG6+Gf70JzjvvKAri04KAxEpUbt2+akiXnoJfv4Z+vb1i8xccEHQlUU3hYGIlIiff4YXX4QXXoA9e/xiMsOGQbNmQVcmoDAQkWJ2+DCMHu3HCvz4o19cZvhwSEgIujLJSWEgIsUiI8NPGfHYY3720E6d4P334Ve/CroyCSeiZy0VkdLHOfj8c2jTxi8pWakSfPKJX2xGQVB6KQxEpMjMmeMXlrn8cti5E95+208xfeWVfgCZlF4KAxEptJUroU8faNfOTy390kuwYoVfa1iLzUcG9RmIyAnbtMnPJPrmm34Succfhz/8wU8tLZFFYSAix233bj9q+G9/g7Q0GDzYdxRrErnIVahmIjMbZmYbzWxB6NYjx2MPm9lqM1thZpfn2N7azBaHHnvZTC2JIpHiwAE/arhhQz+PUM+esHy5H0WsIIhsRdFn8KJzrkXo9hmAmTUF+gLNgO7ASDPLbDl8DRgAnB+6dS+CGkSkGKWl+aagRo3gj3/06w3Pnw9jx/pgkMhXXB3I1wDvOecOOefWAquBdmZWG6jqnJvp/Cr2bwPXFlMNIlJIzvk1huPj4c47/TTSX34JkydDixZBVydFqSjC4G4zW2Rmb5lZ9dC2OsCGHPukhrbVCd3PvT0sMxtgZslmlqxF70VKVua4gF69/ACySZNg1iy4+OKgK5PikG8YmNlUM1sS5nYNvsnnXKAFsBkYkfm0MC/ljrE9LOfc6865Ns65NrVq1cr3hxGRwlu4EHr08G/6Gzb4qSSWLPGhoB6+sivfq4mcc10L8kJmNhr4JPRlKpBzSYpYYFNoe2yY7SISsLVr/RTS48bBaaf5q4XuuQcqVgy6MikJhb2aqHaOL3sCS0L3/wP0NbNTzKwBvqP4O+fcZmCvmXUIXUV0K/BRYWoQkcLZuhXuvddPIT1pku8gXrPG/6sgiB6FHWfwnJm1wDf1rAMGAjjnlppZEvA9kAbc5ZxLDz1nMDAGqAhMDt1EpITt3QsjRvjbgQNw++1+XYE6efbiSVlm/qKe0q9NmzYuOTk56DJEIt6hQ36d4SefhG3boHdvf79x46Ark+JgZnOdc23y209zE4lEiYwM+Pe//Zv+ffdBXBzMng0TJyoIRGEgUuY5B599Bi1b+onjqlWDKVPgiy/8xHIioDAQKdMyxwVceSXs2+evFJo7108xrctEJSeFgUgZtGyZnzfowgv93EF//7vfduONcJL+6iUM/VqIlCEbNsAdd/j+gC++8GsNp6TAXXfByScHXZ2UZprCWqQM2LkTnn7azx7qnB838MgjoIH7UlAKA5EItn+/X1Pg2Wfhp598B/ETT0D9+kFXJpFGYSASgQ4fhrfe8m/8mzfDr38Nf/kLNG8edGUSqdRnIBJBnIMJE3yfwKBB0KABTJsGH3+sIJDCURiIRIjMcQHXXw/lysFHH8GMGdCpU9CVSVmgMBAp5ebNg27doGtX+PFH+Oc/YdEiuPpqjRWQoqMwECmlVq+Gvn2hdWs/UGzECFi5Evr1g5iYfJ8uclzUgSxSymzZ4scHjB7txwY8+igMGeLXGBApLgoDkVJizx54/nl48UX45Rf4zW/8YjO1a+f/XJHCUhiIBOzgQRg50l8aumMH3HCDn1L6vPOCrkyiifoMRAKSng5jxvgVxv7wB2jVCpKT4b33FARS8hQGIiXMOfjPfyAhAfr3hzPOgKlT4fPPfWexSBAUBiIlKHNcwDXX+H6BpCT47ju49NKgK5NopzAQKQFLlsBVV/kgWLMGRo2CpUuhTx+NFZDSQWEgUozWr4fbboP4eJg+3XcSr1oFAwdC+fJBVyeSTVcTiRSD7dvhqaf8VUJmvoP4oYfg9NODrkwkPIWBSBHat8+PE3j+efj5Zz9aeNgwOOecoCsTOTaFgUgROHzYjxgePtzPH3Tttf7MoGnToCsTKRiFgUghZGTA+PF+pHBKCiQmwgcf+LWHRSKJOpBFTtC0aX5K6ZtugkqV4NNP4auvFAQSmRQGIsdp9Wro3Rs6d/ZNQv/6F8yfDz166DJRiVxqJhIpoF27/JxBr7ziZxP985/h/vv9WYFIpFMYiOTj8GE/SGzYMB8It9/ug0CziUpZomYikTw459cWjouDe++FFi18c9AbbygIpOxRGIiEsWCBX2Yyc2nJjz/2k8klJARdmUjxUBiI5LB5M9xxh59OesEC3z+weDH8+tfqHJayTX0GIsD+/X6N4Wef9bOJ3n+/X26yevWgKxMpGQoDiWoZGTB2LDz8MGzc6C8ZffZZOPfcoCsTKVlqJpKolTlo7NZbfYfwtGkwcaKCQKKTwkCiTu5BY++8A7Nn+7UGRKJVocLAzIaZ2UYzWxC69Qhtr29mB3JsH5XjOa3NbLGZrTazl83ULSclY9cuP5V006bw3//6sQIrVsDNN8NJ+lgkUa4o+gxedM69EGZ7inOuRZjtrwEDgFnAZ0B3YHIR1CESlgaNieSvRD8PmVltoKpzbqZzzgFvA9eWZA0SPZyDTz6B5s2zB43Nm6dBYyLhFEUY3G1mi8zsLTPLeSFeAzObb2Zfm1lma2wdIDXHPqmhbWGZ2QAzSzaz5G3bthVBqRItFi6Eyy7z6w5D9qCxFuHOVUUk/zAws6lmtiTM7Rp8k8+5QAtgMzAi9LTNQF3nXEvgfmCcmVUFwvUPuLy+t3PudedcG+dcm1q1ah3njybRaPNmuPNOaNnSTx2hQWMiBZNvn4FzrmtBXsjMRgOfhJ5zCDgUuj/XzFKARvgzgdgcT4sFNh1nzSJH2b8f/vpXeOYZDRoTORGFvZooZ8trT2BJaHstM4sJ3W8InA+scc5tBvaaWYfQVUS3Ah8VpgaJbhkZ8O9/wwUX+NXGuneHZcvghRcUBCLHo7BXEz1nZi3wTT3rgIGh7YnAcDNLA9KBQc65naHHBgNjgIr4q4h0JZGckOnT/RlAcjK0aQPjxmmsgMiJKlQYOOduyWP7JGBSHo8lA3GF+b4S3VJS4MEHYdIkiI31g8ZuukljBUQKQ38+EjF274YHHoAmTWDKFA0aEylKmqhOSr3Dh+Ef//CDxnbu1KAxkeKgz1NSauUcNHbPPX5hGQ0aEykeCgMplXIOGnMO/vMfDRoTKU4KAylVcg8ae/llWLLEh4IGjYkUH/UZSKmQe9DY738Pjz2msQIiJUVhIIHKyPDjAx5+GFJToVcvv9LYeecFXZlIdFEzkQRm+nRo3x5uuQXOPBO+/tqPHVAQiJQ8hYGUuJQUuO46SEz0fQRvvw3ffee/FpFgqJlISszu3fDUU75TuFw5GD7crzxWqVLQlYmIwkCK3eHD8PrrMHSoHzTWv78fNHb22UFXJiKZ1EwkxcY5+PRTiI+Hu+/2/86bB2++qSAQKW0UBlIsFi2Cbt38ojIZGX7Q2BdfaNCYSGmlMJAitWUL/OY32esNa9CYSGRQn4EUiQMH/KCxp5/WoDGRSKQwkELJyIB33/WDxjZs0KAxkUilZiI5YTNmQIcOfj2BM87QoDGRSKYwkOO2Zg306eOXmNy0SYPGRMoCNRNJgeUeNPbEE37QWOXKQVcmIoWlMJB85R401q8fPPmkxgqIlCVqJpI8hRs0NncuvPWWgkCkrFEYSFg5B42lp8NHH/lBYy1bBl2ZiBQHhYEcIXPQWMuW/izgb3/zg8auvlqDxkTKMvUZCABpafDqq/D4434A2X33+UFjNWoEXZmIlASFgfDNN/Db3/qmocsv91cLNWoUdFUiUpLUTBTFtm7100lfdBHs2uUHjE2erCAQiUYKgyiUng4jR8IFF8DYsfDQQ7BsmZ9KQv0CItFJzURRZvZs3yQ0bx5cconvJ2jcOOiqRCRoOjOIEjt2wIABcOGF/oqh996DqVMVBCLiKQzKuIwMGD3a9wO89Rbcfz8sXw433KAmIRHJpmaiMmzuXN8klDmJ3KuvQlxc0FWJSGmkM4MyaNcuuOsuaNsW1q+Hd96Br75SEIhI3hQGZUhGBowZ468SGjUK7rnHNwndfLOahETk2NRMVEYsXOjPBr75xncSf/65Fp8XkYLTmUGE27MHfvc7aNUKVqzwncQzZigIROT4FDoMzOweM1thZkvN7Lkc2x82s9Whxy7Psb21mS0OPfaymRowToRzfsBY48Z++oiBA30Y9O8PJyniReQ4FaqZyMy6ANcA8c65Q2Z2Rmh7U6Av0Aw4G5hqZo2cc+nAa8AAYBbwGdAdmFyYOqLN0qW+Sejrr30n8ccfQ5s2QVclIpGssJ8hBwPPOOcOATjntoa2XwO855w75JxbC6wG2plZbaCqc26mc84BbwPXFrKGqLF3LzzwgG8CWrwY/vEPmDVLQSAihVfYMGgEdDKz2Wb2tZm1DW2vA2zIsV9qaFud0P3c28MyswFmlmxmydu2bStkqZHLORg/3jcJjRjhl51cscKPKFaTkIgUhXybicxsKnBWmIceDT2/OtABaAskmVlDIFw/gDvG9rCcc68DrwO0adMmz/3KsuXL/SWiU6f6BWcmTYIOHYKuSkTKmnzDwDnXNa/HzGww8H6oyec7M8sAauI/8Z+TY9dYYFNoe2yY7ZLLzz/7RedHjIBKleDvf4dBgyAmJujKRKQsKmwjw4fAJQBm1gg4GdgO/Afoa2anmFkD4HzgO+fcZmCvmXUIXUV0K/BRIWsoU5yD99+HJk3gmWfgpptg5UrfYawgEJHiUthBZ28Bb5nZEuAX4LbQWcJSM0sCvgfSgLtCVxKB73QeA1TEX0WkK4lCVq2Ce++FKVMgPh7GjfMLz4iIFLdChYFz7hfg5jweewp4Ksz2ZECz5ORw4AA8/TQ8+yyccgq89JI/Eyin8eEiUkL0dhOwjz/2ZwPr1vkmoRdegNq1g65KRKKNLkwMyNq1cPXV/lapEnz5pR9RrCAQkSAoDErYwYPw5z9D06bwv//B88/DggVw8cVBVyYi0UzNRCVoyhQ/ZmD1arj+en/ZaGxs/s8TESluOjMoAT/8AL17wxVX+BHDn3/uRxQrCESktFAYFKNffvFjBZo0gcmT4amnYNEiuOyyoCsTETmSmomKyRdf+MtDV6yAa6/1l4vWqxd0VSIi4enMoIht3Ag33ABdu0JaGnz6KXzwgYJAREo3hUEROXzYdwg3bgwffQTDhsGSJdCjR9CViYjkT81EReDrr32T0NKlcOWVfuWxhg2DrkpEpOAUBoWwZYtfbGbsWN8M9NFHcNVVoIU8yzjn/JDxadNg+nTYvt3/AjRoAPXrZ9+qVQu2TpHjoDA4AWlp8Oqr8PjjfhDZY4/Bww/7kcRSBjkHy5b5N//MAEgNrdFUvbofNj51qp93PKfTTjs6IOrXz95WtWqJ/hgix6IwOE7ffAO//a2/RLRbN3jlFWjUKOiqpEilpflh4dOnZ7/579jhH6tdGxIT/a1TJ2jWzA8ecc7vs27d0bdVq/zgkv37j/w+1auHD4nMW5UqJfQDiygMCmzrVnjwQRgzxg8WmzgRevVSk1CZcPAgzJmT/cb/zTewb59/rGFD3/aX+eZxXAu3AAAPcUlEQVR/7rnh/9PNoGZNfwu3KLVzvjkpZ0isXev/Xb7cD08/cODI59SoET4kMm+nnlpUR0BEYZCf9HS/8Pyjj/r3hwcf9M1C+juMYHv3wsyZ2W/+s2fDoUP+sbg4uPVW/8bfqRPUyXOJ7uNjBrVq+Vvbtkc/7hxs23ZkSGTeli711ygfPHjkc2rWzLsJql49qFy5aGqXqKAwOIbZs32T0Lx50KWL7ydo0iToquS47dgBM2Zkt/nPn+9TPiYGWrWCu+/2n/w7doTTTw+mRjM44wx/a9fu6Medgx9/DN8MtWiRnws9M9Ay1aqV95lFvXrq5JIjKAzC2LHDdwi/8QacdRa8+64fSKYmoQixcWP2p/5p0/wna/ArB7Vv7/9zExPhwgsj5xTPzP8ynnUWdOhw9OMZGUeHReYZxvz58OGHfn6UnM48M+8zi7p1oWLFYv2RpHRRGOSQkQFvvgkPPQR79sDvfw9Dh+qij1LNOUhJOfLNf80a/1iVKv7T/k03+Tf/tm19IJRFJ53kO7dr1/Yhl1tGhr8WOlwz1Ny5fuHtw4ePfM5ZZ+V9ZlG3LlSoUKw/kpQs80sWl35t2rRxycnJxfb6c+f6JqHvvvNNxa++Cs2bF9u3kxOVkeE/6ee8zHPzZv9YzZr+Py+zszchQWuHFlR6ug+L3EGRGR4//OCvssrp7LPzPrM455yyG7wRxszmOufCXNVwpKj/S9m1y3cIv/aab2J9+224+WY1CZUahw/7TpvMT/0zZvj/NPCXdXXpkn2pZ+PG+o87UTExvrO8Th246KKjH09Ph02bwgfFzJl+Tvb09Oz9zY4Mi5xnF3Xq+Mtqq1VTYJQiUXtmkJHh3/j/+EffR3DXXTB8uAaNBu7AAd9zn/mp/9tvs6/Pb9Qo+1N/YqLvBNWbf+mQlnZkWOQ+w9iw4ciwyFShgv+jy7yddtqRX+e+5X68QgX9DuRDZwbHsHChf/P/5hvfvPr559CiRdBVRak9e/wbfmazz5w5/mzADOLj4Y47/Bv/RRf5NmwpncqV8/0Idev6/6/c0tJ8x/7atT409uyB3buPvu3a5ffJ/Dp3p3duJ5+cf2Ac6/FKlRQmIVEVBnv2+A7hV17x43nefBP69fN9b1JCtm498jLPhQv9aVq5cn6w1u9/n32Zp07Tyo5y5fyZ3PHO5X7wYPjQyLyFC5Uffsi+n3tsRri6CnIGktfjp55aZsIkKsLAORg3zk8q9+OPMHCgX3WsRo2gK4sCP/xw5JU+y5f77RUr+tOyP/3Jv/m3b69BUnK0ChWyL6k9EYcO5X0WklegbNqUfT/3FCK5xcTkHRwFCZQqVUrNp9EyHwZLl/omoa+/9lcWfvxx+NkCpAg4BytXHnmlz/r1/rHTTvNNPf37+zb/1q39Kb5IcTrllOzBfCfil198WOQXKDlDZeXK7G2Z05rkxezYoZH52ODBxd7ZXqY7kNPS/FQye/f6tYjvuMMHuRSR9HRYvPjIN/+tW/1jZ5yRfZVPYqKf5kEHX6JNWlp2SBxPoGTefvrJv86hQyf84UkdyPjmwPHj4bzz/CXoUki//ALJyUde5pn5y1q/Plx+efab//nnl5m2VJETVq6cn+LkRKc5SU/3f2MlcBZdpsMAwo/clwL6+WeYNSv7U/+sWdkzazZpAjfemH2p5znnBFurSFkUE+PHZJSAMh8GchzS0uDLL+H//T8fAHPn+m0nneSvvR04MPsyz1q1gq5WRIqQwiDapaX53vWkJD8/zfbt/pS0XTsYMsS/+f/qV5qgSaSMUxhEo/R0/8k/KQkmTfLz6FeuDFdfDddf79v+NWOlSFRRGESL9HTf4ZsZAD/+6EdfXnWVD4ArrlAAiEQxhUFZlpHh59xISvLrdG7Z4t/wf/1rHwA9emiBExEBFAZlT0aGn0UyMwA2bfKjOK+80gfAlVdqpK+IHEVhUBZkZPiZPpOSYMIEPyHYKaf4T/7XX+/PBCJlRS8RCUShw8DM7gHuBtKAT51zfzSz+sAyYEVot1nOuUGh/VsDY4CKwGfAfS5ShkGXJs75lXgyA2DDBn8V0BVXwHPP+b6AKlWCrlJEIkShwsDMugDXAPHOuUNmlnMCkBTnXLiJoV8DBgCz8GHQHZhcmDqihnN+BHBmAKxf7wPg8svhL3/xAXDaaUFXKSIRqLBnBoOBZ5xzhwCcc1uPtbOZ1QaqOudmhr5+G7gWhUHenPMrfSUl+du6dVC+PHTr5lfjufpqTfUsIoVW2DBoBHQys6eAg8ADzrk5occamNl84CfgMefcdKAOkJrj+amhbWGZ2QD8WQR169YtZKkRxDlYsCA7ANas8XOcXHaZX5DhmmtKbIi6iESHfMPAzKYC4SYTfzT0/OpAB6AtkGRmDYHNQF3n3I5QH8GHZtYMCDdzWZ79Bc6514HXwc9aml+tEc05WLQoOwBWr/bzknTtCo8+CtdeqwUYRKTY5BsGzrmueT1mZoOB90MdwN+ZWQZQ0zm3DchsOpprZin4s4hUIDbHS8QCmwpRf2RzDpYsyQ6AlSt9AFxyCTz4oA8ATbcqIiWgsM1EHwKXAF+ZWSPgZGC7mdUCdjrn0kNnCucDa5xzO81sr5l1AGYDtwKvFLKGyLN0aXYALF/uJ4Lr0gX+8Afo2VOTwIlIiStsGLwFvGVmS4BfgNucc87MEoHhZpYGpAODnHM7Q88ZTPalpZOJls7jZcv8FUBJST4MzODii+G++6BXrxNfiUlEpAgUKgycc78AN4fZPgmYlMdzkoG4wnzfiLFiRXYALF7sAyAxEV591QfAia7rKiJSxDQCuaitWpUdAAsX+gC46CJ45RXo3Rtq1w66QhGRoygMikJKSnYAzJ/vt3XsCH/7mw+AOnlePSsiUiooDE7U2rXZATB3rt924YXw4os+ALQMpIhEEIXB8Vi/PjsA5oTG1rVvDyNGwHXXQTQNjBORMkVhkJ8ffvBTQScl+ZlBAdq2heef9wFQv36g5YmIFAWFQTipqdkBMHOm39a6NTz7rA+Ahg2DrU9EpIgpDDJt3OiXg0xK8quDAbRsCU8/DX36wLnnBlufiEgxiu4w2Lw5OwBmzPDTQyQkwFNP+QA4//ygKxQRKRHRFwZbtsD77/sAmDbNB0Dz5n466D594IILgq5QRKTERUcYbN2aHQBff+2XiWzaFIYN8wHQpEnQFYqIBKpsh4FzfvWvyZN9ADRuDI895tcFbtYs6OpEREqNsh0GZr7dv2VLHwBxcX6biIgcoWyHAfgRwSIickwnBV2AiIgET2EgIiIKAxERURiIiAgKAxERQWEgIiIoDEREBIWBiIgA5pwLuoYCMbNtwPoTfHpNYHsRllNUVNfxUV3HR3Udn7JaVz3nXK38doqYMCgMM0t2zrUJuo7cVNfxUV3HR3Udn2ivS81EIiKiMBARkegJg9eDLiAPquv4qK7jo7qOT1TXFRV9BiIicmzRcmYgIiLHUGbCwMzOMbMvzWyZmS01s/vC7GNm9rKZrTazRWbWqpTUdbGZ7TGzBaHb4yVQVwUz+87MFobqeiLMPkEcr4LUVeLHK8f3jjGz+Wb2SZjHSvx4FbCuQI6Xma0zs8Wh75kc5vFAjlcB6grqeFUzs4lmtjz0fnFhrseL93g558rEDagNtArdrwKsBJrm2qcHMBkwoAMwu5TUdTHwSQkfLwNODd0vD8wGOpSC41WQukr8eOX43vcD48J9/yCOVwHrCuR4AeuAmsd4PJDjVYC6gjpe/wLuDN0/GahWkserzJwZOOc2O+fmhe7vBZYBdXLtdg3wtvNmAdXMrHYpqKvEhY7BvtCX5UO33B1IQRyvgtQVCDOLBa4E3shjlxI/XgWsq7QK5HiVRmZWFUgE3gRwzv3inNuda7diPV5lJgxyMrP6QEv8p8qc6gAbcnydSgm+MR+jLoALQ00jk82sWQnVE2NmC4CtwP9zzpWK41WAuiCA4wW8BPwRyMjj8aB+v/KrC4I5Xg743MzmmtmAMI8HdbzyqwtK/ng1BLYB/ww1971hZpVz7VOsx6vMhYGZnQpMAn7nnPsp98NhnlIinzrzqWsefsh4AvAK8GFJ1OScS3fOtQBigXZmFpdrl0COVwHqKvHjZWa/BrY65+Yea7cw24r1eBWwrkB+v4COzrlWwBXAXWaWmOvxoP4e86sriONVDmgFvOacawn8DDyUa59iPV5lKgzMrDz+DXesc+79MLukAufk+DoW2BR0Xc65nzKbRpxznwHlzaxmcdeV4/vvBr4Cuud6KJDjlSmvugI6Xh2Bq81sHfAecImZ/TvXPkEcr3zrCur3yzm3KfTvVuADoF2uXQL5/cqvroCOVyqQmuMseCI+HHLvU2zHq8yEgZkZvr1tmXPur3ns9h/g1lCvfAdgj3Nuc9B1mdlZof0ws3b4/5cdxVxXLTOrFrpfEegKLM+1WxDHK9+6gjhezrmHnXOxzrn6QF/gf865m3PtVuLHqyB1BfT7VdnMqmTeB7oBS3LtFsTvV751BfT7tQXYYGYXhDZdCnyfa7diPV7liuqFSoGOwC3A4lB7M8AjQF0A59wo4DN8j/xqYD/Qv5TUdR0w2MzSgANAXxe6fKAY1Qb+ZWYx+F/2JOfcJ2Y2KEddQRyvgtQVxPEKqxQcr4LUFcTxOhP4IPSeWg4Y55ybUgqOV0HqCur36x5grJmdDKwB+pfk8dIIZBERKTvNRCIicuIUBiIiojAQERGFgYiIoDAQEREUBiJ5MrNhZvbACTyvhZn1KOzriJQkhYFI0WuBvx5cJGIoDERyMLNHzWyFmU0FLghtO9fMpoQmNptuZo1D28eY2ajQtpVm9uvQgKHhwA3m58K/IfTSTc3sKzNbY2b3BvPTieStLI1AFikUM2uNn9KhJf5vYx4wF78G7SDn3Cozaw+MBC4JPa0+0Bk4F/gSOA94HGjjnLs79LrDgMZAF/yaFivM7DXn3OGS+clE8qcwEMnWCfjAObcfwMz+A1QAfgVMCE1hAHBKjuckOecygFVmtgb/ph/Op865Q8AhM9uKnxYhtRh+BpETojAQOVLu+VlOAnaHptQuyP55ze9yKMf9dPS3J6WM+gxEsk0DeppZxdDMllfhJwRba2Z9IGsd2oQcz+ljZieZ2bn4BUpWAHvxzUEiEUNhIBISWp50PLAAv/7E9NBD/wfcYWYLgaX45QczrQC+xq9NO8g5dxDfd9A0VweySKmmWUtFTpCZjcEvnD4x6FpECktnBiIiojMDERHRmYGIiKAwEBERFAYiIoLCQEREUBiIiAgKAxERAf4/6eayuKt7B6sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modified from cell 13 at\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "depth = [2, 3, 4, 5, 6]\n",
    "train_score, val_score = validation_curve(\n",
    "    model, X_train, y_train,\n",
    "    param_name='max_depth', param_range=depth, \n",
    "    scoring='neg_mean_absolute_error', cv=3)\n",
    "\n",
    "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('depth');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQoMvZ7-yCAQ"
   },
   "source": [
    "### `RandomizedSearchCV`\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bk_dX_mByKm7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  24 | elapsed:    5.7s remaining:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  24 | elapsed:    6.5s remaining:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  24 | elapsed:    7.2s remaining:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  24 | elapsed:   10.8s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  24 | elapsed:   12.6s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  24 | elapsed:   12.7s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed:   12.9s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   13.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=8, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 200], 'max_depth': [4, 5], 'criterion': ['mse', 'mae']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "          verbose=10)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': [100,200,],\n",
    "    'max_depth': [4,5,],\n",
    "    'criterion': ['mse','mae',],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
    "    param_distributions = param_distributions,\n",
    "    n_jobs = -1,\n",
    "    n_iter = 8,\n",
    "    cv = 3,\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    verbose = 10,\n",
    "    return_train_score = True,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.060804</td>\n",
       "      <td>0.151792</td>\n",
       "      <td>0.167886</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>mae</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>-537.343224</td>\n",
       "      <td>-633.188069</td>\n",
       "      <td>-611.812399</td>\n",
       "      <td>-594.114564</td>\n",
       "      <td>41.080965</td>\n",
       "      <td>1</td>\n",
       "      <td>-514.399139</td>\n",
       "      <td>-476.132208</td>\n",
       "      <td>-486.784755</td>\n",
       "      <td>-492.438701</td>\n",
       "      <td>16.125856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.883291</td>\n",
       "      <td>0.128478</td>\n",
       "      <td>0.982707</td>\n",
       "      <td>0.096035</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>mae</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>-539.744330</td>\n",
       "      <td>-635.247773</td>\n",
       "      <td>-610.870031</td>\n",
       "      <td>-595.287378</td>\n",
       "      <td>40.516179</td>\n",
       "      <td>2</td>\n",
       "      <td>-513.924961</td>\n",
       "      <td>-475.585023</td>\n",
       "      <td>-489.148606</td>\n",
       "      <td>-492.886197</td>\n",
       "      <td>15.873771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.673194</td>\n",
       "      <td>0.363340</td>\n",
       "      <td>2.164213</td>\n",
       "      <td>0.914925</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>mae</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
       "      <td>-545.553738</td>\n",
       "      <td>-635.478629</td>\n",
       "      <td>-609.898505</td>\n",
       "      <td>-596.976957</td>\n",
       "      <td>37.831612</td>\n",
       "      <td>3</td>\n",
       "      <td>-554.610927</td>\n",
       "      <td>-515.603583</td>\n",
       "      <td>-525.162173</td>\n",
       "      <td>-531.792227</td>\n",
       "      <td>16.600431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.609010</td>\n",
       "      <td>0.164526</td>\n",
       "      <td>1.740016</td>\n",
       "      <td>0.405574</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>mae</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
       "      <td>-545.615950</td>\n",
       "      <td>-634.226674</td>\n",
       "      <td>-611.571316</td>\n",
       "      <td>-597.137980</td>\n",
       "      <td>37.587285</td>\n",
       "      <td>4</td>\n",
       "      <td>-554.012714</td>\n",
       "      <td>-515.754478</td>\n",
       "      <td>-524.948497</td>\n",
       "      <td>-531.571896</td>\n",
       "      <td>16.305934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.169871</td>\n",
       "      <td>0.024030</td>\n",
       "      <td>0.290890</td>\n",
       "      <td>0.034147</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>mse</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>-545.774354</td>\n",
       "      <td>-637.307005</td>\n",
       "      <td>-627.616934</td>\n",
       "      <td>-603.566098</td>\n",
       "      <td>41.055966</td>\n",
       "      <td>5</td>\n",
       "      <td>-524.163469</td>\n",
       "      <td>-490.204130</td>\n",
       "      <td>-490.472466</td>\n",
       "      <td>-501.613355</td>\n",
       "      <td>15.945715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.553187</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.133976</td>\n",
       "      <td>0.016070</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>mse</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>-546.995243</td>\n",
       "      <td>-639.080607</td>\n",
       "      <td>-629.837818</td>\n",
       "      <td>-605.304556</td>\n",
       "      <td>41.403214</td>\n",
       "      <td>6</td>\n",
       "      <td>-526.882336</td>\n",
       "      <td>-490.560190</td>\n",
       "      <td>-492.252512</td>\n",
       "      <td>-503.231679</td>\n",
       "      <td>16.737805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.522261</td>\n",
       "      <td>0.041658</td>\n",
       "      <td>0.246009</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>mse</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
       "      <td>-555.634757</td>\n",
       "      <td>-640.866167</td>\n",
       "      <td>-625.853913</td>\n",
       "      <td>-607.451613</td>\n",
       "      <td>37.149085</td>\n",
       "      <td>7</td>\n",
       "      <td>-572.252550</td>\n",
       "      <td>-529.625674</td>\n",
       "      <td>-536.655286</td>\n",
       "      <td>-546.177836</td>\n",
       "      <td>18.659615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.562828</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>0.126662</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>mse</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
       "      <td>-557.174302</td>\n",
       "      <td>-642.450417</td>\n",
       "      <td>-629.072181</td>\n",
       "      <td>-609.565633</td>\n",
       "      <td>37.446700</td>\n",
       "      <td>8</td>\n",
       "      <td>-574.472102</td>\n",
       "      <td>-530.248079</td>\n",
       "      <td>-538.576526</td>\n",
       "      <td>-547.765569</td>\n",
       "      <td>19.188016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7       5.060804      0.151792         0.167886        0.056940   \n",
       "6       2.883291      0.128478         0.982707        0.096035   \n",
       "4       1.673194      0.363340         2.164213        0.914925   \n",
       "5       4.609010      0.164526         1.740016        0.405574   \n",
       "3       1.169871      0.024030         0.290890        0.034147   \n",
       "2       0.553187      0.026329         0.133976        0.016070   \n",
       "1       1.522261      0.041658         0.246009        0.005423   \n",
       "0       0.562828      0.019635         0.126662        0.007101   \n",
       "\n",
       "  param_n_estimators param_max_depth param_criterion  \\\n",
       "7                200               5             mae   \n",
       "6                100               5             mae   \n",
       "4                100               4             mae   \n",
       "5                200               4             mae   \n",
       "3                200               5             mse   \n",
       "2                100               5             mse   \n",
       "1                200               4             mse   \n",
       "0                100               4             mse   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "7  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -537.343224   \n",
       "6  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -539.744330   \n",
       "4  {'n_estimators': 100, 'max_depth': 4, 'criteri...        -545.553738   \n",
       "5  {'n_estimators': 200, 'max_depth': 4, 'criteri...        -545.615950   \n",
       "3  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -545.774354   \n",
       "2  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -546.995243   \n",
       "1  {'n_estimators': 200, 'max_depth': 4, 'criteri...        -555.634757   \n",
       "0  {'n_estimators': 100, 'max_depth': 4, 'criteri...        -557.174302   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "7        -633.188069        -611.812399      -594.114564       41.080965   \n",
       "6        -635.247773        -610.870031      -595.287378       40.516179   \n",
       "4        -635.478629        -609.898505      -596.976957       37.831612   \n",
       "5        -634.226674        -611.571316      -597.137980       37.587285   \n",
       "3        -637.307005        -627.616934      -603.566098       41.055966   \n",
       "2        -639.080607        -629.837818      -605.304556       41.403214   \n",
       "1        -640.866167        -625.853913      -607.451613       37.149085   \n",
       "0        -642.450417        -629.072181      -609.565633       37.446700   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "7                1         -514.399139         -476.132208   \n",
       "6                2         -513.924961         -475.585023   \n",
       "4                3         -554.610927         -515.603583   \n",
       "5                4         -554.012714         -515.754478   \n",
       "3                5         -524.163469         -490.204130   \n",
       "2                6         -526.882336         -490.560190   \n",
       "1                7         -572.252550         -529.625674   \n",
       "0                8         -574.472102         -530.248079   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "7         -486.784755       -492.438701        16.125856  \n",
       "6         -489.148606       -492.886197        15.873771  \n",
       "4         -525.162173       -531.792227        16.600431  \n",
       "5         -524.948497       -531.571896        16.305934  \n",
       "3         -490.472466       -501.613355        15.945715  \n",
       "2         -492.252512       -503.231679        16.737805  \n",
       "1         -536.655286       -546.177836        18.659615  \n",
       "0         -538.576526       -547.765569        19.188016  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZW5HfYtU0GW2"
   },
   "source": [
    "## FEATURE ENGINEERING!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ms-eoOHFvPG"
   },
   "source": [
    "Jake VanderPlas demonstrates this feature engineering: \n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEwME8wR3A5g"
   },
   "outputs": [],
   "source": [
    "# Modified from code cells 17-21 at\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
    "\n",
    "def jake_wrangle(X):  \n",
    "    X = X.copy()\n",
    "\n",
    "    # patterns of use generally vary from day to day; \n",
    "    # let's add binary columns that indicate the day of the week:\n",
    "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    for i, day in enumerate(days):\n",
    "        X[day] = (X.index.dayofweek == i).astype(float)\n",
    "\n",
    "\n",
    "    # we might expect riders to behave differently on holidays; \n",
    "    # let's add an indicator of this as well:\n",
    "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "    cal = USFederalHolidayCalendar()\n",
    "    holidays = cal.holidays('2012', '2016')\n",
    "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
    "    X['holiday'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    # We also might suspect that the hours of daylight would affect \n",
    "    # how many people ride; let's use the standard astronomical calculation \n",
    "    # to add this information:\n",
    "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
    "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
    "        days = (date - pd.datetime(2000, 12, 21)).days\n",
    "        m = (1. - np.tan(np.radians(latitude))\n",
    "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
    "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
    "\n",
    "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
    "\n",
    "    \n",
    "    # temperatures are in 1/10 deg C; convert to C\n",
    "    X['TMIN'] /= 10\n",
    "    X['TMAX'] /= 10\n",
    "    \n",
    "    # We can also calcuate the average temperature.\n",
    "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
    "\n",
    "    # precip is in 1/10 mm; convert to inches\n",
    "    X['PRCP'] /= 254\n",
    "\n",
    "    # In addition to the inches of precipitation, let's add a flag that \n",
    "    # indicates whether a day is dry (has zero precipitation):\n",
    "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
    "\n",
    "\n",
    "    # Let's add a counter that increases from day 1, and measures how many \n",
    "    # years have passed. This will let us measure any observed annual increase \n",
    "    # or decrease in daily crossings:\n",
    "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
    "\n",
    "    return X\n",
    "\n",
    "X_train = jake_wrangle(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDGkAv813Wtj"
   },
   "source": [
    "### Linear Regression (with new features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj3HTM6p5F1A"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-297.692524</td>\n",
       "      <td>-294.532315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-300.419037</td>\n",
       "      <td>-283.779461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-322.640378</td>\n",
       "      <td>-283.509114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time                                          estimator  \\\n",
       "0  0.010930    0.005984  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "1  0.007982    0.002989  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "2  0.010966    0.002992  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "\n",
       "   test_score  train_score  \n",
       "0 -297.692524  -294.532315  \n",
       "1 -300.419037  -283.779461  \n",
       "2 -322.640378  -283.509114  "
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(LinearRegression(), X_train, y_train, scoring='neg_mean_absolute_error',\n",
    "                        cv=3, return_train_score=True, return_estimator=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306.9173130794431"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6zxN2xB3bX_"
   },
   "source": [
    "### Random Forest (with new features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sWUDZIz1-kk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:   14.0s remaining:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:   14.1s remaining:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:   14.1s remaining:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:   14.2s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   14.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=4, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100], 'max_depth': [5, 19, 15, None], 'criterion': ['mae']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "          verbose=10)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [5, 19, 15, None],\n",
    "    'criterion': ['mae'],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
    "    param_distributions = param_distributions,\n",
    "    n_jobs = -1,\n",
    "    n_iter = 4,\n",
    "    cv = 3,\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    verbose = 10,\n",
    "    return_train_score = True,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.626956</td>\n",
       "      <td>1.619306</td>\n",
       "      <td>1.312161</td>\n",
       "      <td>1.604867</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 15, 'criter...</td>\n",
       "      <td>-347.235405</td>\n",
       "      <td>-319.651340</td>\n",
       "      <td>-304.428754</td>\n",
       "      <td>-323.771833</td>\n",
       "      <td>17.716963</td>\n",
       "      <td>1</td>\n",
       "      <td>-112.552009</td>\n",
       "      <td>-102.188061</td>\n",
       "      <td>-116.336075</td>\n",
       "      <td>-110.358715</td>\n",
       "      <td>5.980495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.246991</td>\n",
       "      <td>0.567503</td>\n",
       "      <td>4.620981</td>\n",
       "      <td>0.530648</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>mae</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 19, 'criter...</td>\n",
       "      <td>-354.854439</td>\n",
       "      <td>-320.053115</td>\n",
       "      <td>-302.378193</td>\n",
       "      <td>-325.761916</td>\n",
       "      <td>21.800335</td>\n",
       "      <td>2</td>\n",
       "      <td>-108.333808</td>\n",
       "      <td>-100.009984</td>\n",
       "      <td>-113.756168</td>\n",
       "      <td>-107.366654</td>\n",
       "      <td>5.653373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.904874</td>\n",
       "      <td>0.076956</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>mae</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': None, 'crit...</td>\n",
       "      <td>-358.797290</td>\n",
       "      <td>-320.268505</td>\n",
       "      <td>-301.250794</td>\n",
       "      <td>-326.772196</td>\n",
       "      <td>23.939135</td>\n",
       "      <td>3</td>\n",
       "      <td>-108.845631</td>\n",
       "      <td>-99.839463</td>\n",
       "      <td>-113.803692</td>\n",
       "      <td>-107.496262</td>\n",
       "      <td>5.780168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.287246</td>\n",
       "      <td>0.127156</td>\n",
       "      <td>6.288521</td>\n",
       "      <td>0.075123</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>mae</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>-360.615374</td>\n",
       "      <td>-387.242134</td>\n",
       "      <td>-335.736137</td>\n",
       "      <td>-361.197882</td>\n",
       "      <td>21.031269</td>\n",
       "      <td>4</td>\n",
       "      <td>-299.174914</td>\n",
       "      <td>-266.206192</td>\n",
       "      <td>-294.979984</td>\n",
       "      <td>-286.787030</td>\n",
       "      <td>14.653271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2      12.626956      1.619306         1.312161        1.604867   \n",
       "1       9.246991      0.567503         4.620981        0.530648   \n",
       "3      13.904874      0.076956         0.124999        0.005299   \n",
       "0       5.287246      0.127156         6.288521        0.075123   \n",
       "\n",
       "  param_n_estimators param_max_depth param_criterion  \\\n",
       "2                100              15             mae   \n",
       "1                100              19             mae   \n",
       "3                100            None             mae   \n",
       "0                100               5             mae   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "2  {'n_estimators': 100, 'max_depth': 15, 'criter...        -347.235405   \n",
       "1  {'n_estimators': 100, 'max_depth': 19, 'criter...        -354.854439   \n",
       "3  {'n_estimators': 100, 'max_depth': None, 'crit...        -358.797290   \n",
       "0  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -360.615374   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "2        -319.651340        -304.428754      -323.771833       17.716963   \n",
       "1        -320.053115        -302.378193      -325.761916       21.800335   \n",
       "3        -320.268505        -301.250794      -326.772196       23.939135   \n",
       "0        -387.242134        -335.736137      -361.197882       21.031269   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "2                1         -112.552009         -102.188061   \n",
       "1                2         -108.333808         -100.009984   \n",
       "3                3         -108.845631          -99.839463   \n",
       "0                4         -299.174914         -266.206192   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "2         -116.336075       -110.358715         5.980495  \n",
       "1         -113.756168       -107.366654         5.653373  \n",
       "3         -113.803692       -107.496262         5.780168  \n",
       "0         -294.979984       -286.787030        14.653271  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edpJ87A8A8sd"
   },
   "source": [
    "\n",
    "### Feature engineering, explained by Francois Chollet\n",
    "\n",
    "> _Feature engineering_ is the process of using your own knowledge about the data and about the machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine-learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.\n",
    "\n",
    "> Let’s look at an intuitive example. Suppose you’re trying to develop a model that can take as input an image of a clock and can output the time of day.\n",
    "\n",
    "> If you choose to use the raw pixels of the image as input data, then you have a difficult machine-learning problem on your hands. You’ll need a convolutional neural network to solve it, and you’ll have to expend quite a bit of computational resources to train the network.\n",
    "\n",
    "> But if you already understand the problem at a high level (you understand how humans read time on a clock face), then you can come up with much better input features for a machine-learning algorithm: for instance, write a Python script to follow the black pixels of the clock hands and output the (x, y) coordinates of the tip of each hand. Then a simple machine-learning algorithm can learn to associate these coordinates with the appropriate time of day.\n",
    "\n",
    "> You can go even further: do a coordinate change, and express the (x, y) coordinates as polar coordinates with regard to the center of the image. Your input will become the angle theta of each clock hand. At this point, your features are making the problem so easy that no machine learning is required; a simple rounding operation and dictionary lookup are enough to recover the approximate time of day.\n",
    "\n",
    "> That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.\n",
    "\n",
    "> Before convolutional neural networks became successful on the MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an image, a histogram of pixel values, and so on.\n",
    "\n",
    "> Neural networks are capable of automatically extracting useful features from raw data. Does this mean you don’t have to worry about feature engineering as long as you’re using deep neural networks? No, for two reasons:\n",
    "\n",
    "> - Good features still allow you to solve problems more elegantly while using fewer resources. For instance, it would be ridiculous to solve the problem of reading a clock face using a convolutional neural network.\n",
    "> - Good features let you solve a problem with far less data. The ability of deep-learning models to learn features on their own relies on having lots of training data available; if you have only a few samples, then the information value in their features becomes critical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oux-dd-5FD6p"
   },
   "source": [
    "# ASSIGNMENT\n",
    "\n",
    "✔️ **1.** Complete the notebook cells that were originally commented **`TODO`**. \n",
    "\n",
    "✔️ **2.** Then, focus on feature engineering to improve your cross validation scores. Collaborate with your cohort on Slack. You could start with the ideas [Jake VanderPlas suggests:](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic)\n",
    "\n",
    "> Our model is almost certainly missing some relevant information. For example, nonlinear effects (such as effects of precipitation and cold temperature) and nonlinear trends within each variable (such as disinclination to ride at very cold and very hot temperatures) cannot be accounted for in this model. Additionally, we have thrown away some of the finer-grained information (such as the difference between a rainy morning and a rainy afternoon), and we have ignored correlations between days (such as the possible effect of a rainy Tuesday on Wednesday's numbers, or the effect of an unexpected sunny day after a streak of rainy days). These are all potentially interesting effects, and you now have the tools to begin exploring them if you wish!\n",
    "\n",
    "✔️ **3.** Experiment with the Categorical Encoding notebook.\n",
    "\n",
    "**4.** At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
    "\n",
    "See the [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
    "\n",
    "> **refit : boolean, or string, default=True**\n",
    "\n",
    "> Refit an estimator using the best found parameters on the whole dataset.\n",
    "\n",
    "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance.\n",
    "\n",
    "### STRETCH\n",
    "\n",
    "**A.** Apply this lesson other datasets you've worked with, like Ames Housing, Bank Marketing, or others.\n",
    "\n",
    "✔️ **B.** In additon to `RandomizedSearchCV`, scikit-learn has [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
    "\n",
    "✔️ **C.** _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
    "\n",
    "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
    "\n",
    "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "Target\n",
    "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
    "\n",
    "Features\n",
    "- Date (index) : from 2012-10-04 to 2015-09-01\n",
    "- Total_yesterday : Total trips yesterday\n",
    "- PRCP : Precipitation (1/10 mm)\n",
    "- SNOW : Snowfall (1/10 mm)\n",
    "- SNWD : Snow depth (1/10 mm)\n",
    "- TMAX : Maximum temperature (1/10 Celsius)\n",
    "- TMIN : Minimum temperature (1/10 Celsius)\n",
    "- AWND : Average daily wind speed (1/10 meters per second)\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>holiday</th>\n",
       "      <th>daylight_hrs</th>\n",
       "      <th>Temp (C)</th>\n",
       "      <th>dry day</th>\n",
       "      <th>annual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>65</td>\n",
       "      <td>3521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.219142</td>\n",
       "      <td>13.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>57</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.161038</td>\n",
       "      <td>15.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>51</td>\n",
       "      <td>3148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.103056</td>\n",
       "      <td>15.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>13</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.045208</td>\n",
       "      <td>15.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>19</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.987503</td>\n",
       "      <td>14.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday  Mon  Tue  \\\n",
       "2012-10-04   0.0     0     0  18.9   8.3    65           3521.0  0.0  0.0   \n",
       "2012-10-05   0.0     0     0  21.7   8.9    57           3475.0  0.0  0.0   \n",
       "2012-10-06   0.0     0     0  23.9   7.8    51           3148.0  0.0  0.0   \n",
       "2012-10-07   0.0     0     0  23.9   7.8    13           2006.0  0.0  0.0   \n",
       "2012-10-08   0.0     0     0  21.1   7.8    19           2142.0  1.0  0.0   \n",
       "\n",
       "            Wed  Thu  Fri  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day  \\\n",
       "2012-10-04  0.0  1.0  0.0  0.0  0.0      0.0     11.219142     13.60        1   \n",
       "2012-10-05  0.0  0.0  1.0  0.0  0.0      0.0     11.161038     15.30        1   \n",
       "2012-10-06  0.0  0.0  0.0  1.0  0.0      0.0     11.103056     15.85        1   \n",
       "2012-10-07  0.0  0.0  0.0  0.0  1.0      0.0     11.045208     15.85        1   \n",
       "2012-10-08  0.0  0.0  0.0  0.0  0.0      1.0     10.987503     14.45        1   \n",
       "\n",
       "              annual  \n",
       "2012-10-04  0.000000  \n",
       "2012-10-05  0.002740  \n",
       "2012-10-06  0.005479  \n",
       "2012-10-07  0.008219  \n",
       "2012-10-08  0.010959  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineered temperature features\n",
    "X_train['intraday_temp_difference'] = X_train['TMAX'] - X_train['TMIN']\n",
    "X_train['interday_temp_pct_change'] = X_train['TMAX'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PRCP</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNOW</th>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNWD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMAX</th>\n",
       "      <td>-1.600000</td>\n",
       "      <td>35.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMIN</th>\n",
       "      <td>-7.100000</td>\n",
       "      <td>18.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWND</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_yesterday</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>6088.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mon</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tue</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wed</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thu</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fri</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sun</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daylight_hrs</th>\n",
       "      <td>8.218894</td>\n",
       "      <td>15.781095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp (C)</th>\n",
       "      <td>-3.800000</td>\n",
       "      <td>26.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dry day</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.635616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intraday_temp_difference</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>18.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interday_temp_pct_change</th>\n",
       "      <td>-3.062500</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  min          max\n",
       "PRCP                         0.000000     2.200787\n",
       "SNOW                     -9999.000000    74.000000\n",
       "SNWD                         0.000000    80.000000\n",
       "TMAX                        -1.600000    35.600000\n",
       "TMIN                        -7.100000    18.300000\n",
       "AWND                         4.000000    95.000000\n",
       "Total_yesterday             98.000000  6088.000000\n",
       "Mon                          0.000000     1.000000\n",
       "Tue                          0.000000     1.000000\n",
       "Wed                          0.000000     1.000000\n",
       "Thu                          0.000000     1.000000\n",
       "Fri                          0.000000     1.000000\n",
       "Sat                          0.000000     1.000000\n",
       "Sun                          0.000000     1.000000\n",
       "holiday                      0.000000     1.000000\n",
       "daylight_hrs                 8.218894    15.781095\n",
       "Temp (C)                    -3.800000    26.700000\n",
       "dry day                      0.000000     1.000000\n",
       "annual                       0.000000     2.635616\n",
       "intraday_temp_difference     0.600000    18.800000\n",
       "interday_temp_pct_change    -3.062500          inf"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for suspicious values / outliers\n",
    "X_train.describe().T[['min','max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gotcha! `df.pct_change()` returns an `inf` observation, which _is_ a legal float value. This is problematic because it won't show up with `df.isna()` or `df.info()`. Luckily, it does show up as a legitimate float-type max value when `df.describe()` is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train['interday_temp_pct_change'].fillna(value=X_train['interday_temp_pct_change'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see another peculiar outlier in the dataframe: a minimum value in `SNOW` of -9999... This can't be right. My guess is that this is the source's imputation method for days in which there is no data and it _didn't_ snow. `SNOW` and `SNWD` are likely very collinear, so I'm opting to drop the `SNOW` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>...</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>holiday</th>\n",
       "      <th>daylight_hrs</th>\n",
       "      <th>Temp (C)</th>\n",
       "      <th>dry day</th>\n",
       "      <th>annual</th>\n",
       "      <th>intraday_temp_difference</th>\n",
       "      <th>interday_temp_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-13</th>\n",
       "      <td>0.370079</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>57</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.263023</td>\n",
       "      <td>6.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523288</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.358974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-16</th>\n",
       "      <td>0.011811</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>26</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.432650</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-16</th>\n",
       "      <td>0.141732</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>24</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.757561</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1.698630</td>\n",
       "      <td>8.9</td>\n",
       "      <td>-0.027322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>40</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.239536</td>\n",
       "      <td>9.15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.180328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday  Mon  Tue  \\\n",
       "2013-04-13  0.370079 -9999     0  10.6   3.3    57           2045.0  0.0  0.0   \n",
       "2013-04-16  0.011811 -9999     0  13.9   3.3    26           2687.0  0.0  1.0   \n",
       "2014-06-16  0.141732 -9999     0  17.8   8.9    24           1267.0  1.0  0.0   \n",
       "2014-12-16  0.000000 -9999     0  10.0   8.3    40           2283.0  0.0  1.0   \n",
       "\n",
       "            Wed  ...  Fri  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day  \\\n",
       "2013-04-13  0.0  ...  0.0  1.0  0.0      0.0     13.263023      6.95        0   \n",
       "2013-04-16  0.0  ...  0.0  0.0  0.0      0.0     13.432650      8.60        0   \n",
       "2014-06-16  0.0  ...  0.0  0.0  0.0      0.0     15.757561     13.35        0   \n",
       "2014-12-16  0.0  ...  0.0  0.0  0.0      0.0      8.239536      9.15        1   \n",
       "\n",
       "              annual  intraday_temp_difference  interday_temp_pct_change  \n",
       "2013-04-13  0.523288                       7.3                  0.358974  \n",
       "2013-04-16  0.531507                      10.6                  0.000000  \n",
       "2014-06-16  1.698630                       8.9                 -0.027322  \n",
       "2014-12-16  2.200000                       1.7                 -0.180328  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[ X_train['SNOW'] == -9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns='SNOW', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor Hyperparameter Optimization via `BayesSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian hyperparameter search for the Random Forest Regressor\n",
    "search_spaces_rf = {\n",
    "    'n_estimators': Integer(50,200),\n",
    "    'max_features': Integer(2,20),\n",
    "    'max_depth': Integer(1,10),\n",
    "    'min_samples_split': Integer(2,6),\n",
    "    'min_samples_leaf': Integer(1,6),\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
    "    search_spaces=search_spaces_rf,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    n_iter=50,  # default\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "bayes_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
      "           max_features=19, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=2,\n",
      "           min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=151, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-293.532209</td>\n",
       "      <td>-331.073780</td>\n",
       "      <td>-296.596204</td>\n",
       "      <td>-307.067398</td>\n",
       "      <td>17.021101</td>\n",
       "      <td>1</td>\n",
       "      <td>-170.098015</td>\n",
       "      <td>-155.302753</td>\n",
       "      <td>-166.514220</td>\n",
       "      <td>-163.971663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778917</td>\n",
       "      <td>0.030326</td>\n",
       "      <td>0.114030</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 19, 'min_samp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-293.180038</td>\n",
       "      <td>-331.275685</td>\n",
       "      <td>-296.861521</td>\n",
       "      <td>-307.105748</td>\n",
       "      <td>17.156684</td>\n",
       "      <td>1</td>\n",
       "      <td>-169.861127</td>\n",
       "      <td>-155.325622</td>\n",
       "      <td>-166.365423</td>\n",
       "      <td>-163.850724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751657</td>\n",
       "      <td>0.037015</td>\n",
       "      <td>0.117691</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>156</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 19, 'min_samp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-295.642626</td>\n",
       "      <td>-331.898693</td>\n",
       "      <td>-293.793095</td>\n",
       "      <td>-307.111471</td>\n",
       "      <td>17.543469</td>\n",
       "      <td>1</td>\n",
       "      <td>-170.790727</td>\n",
       "      <td>-155.990971</td>\n",
       "      <td>-168.511348</td>\n",
       "      <td>-165.097682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767626</td>\n",
       "      <td>0.047225</td>\n",
       "      <td>0.113683</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>158</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 18, 'min_samp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-296.695262</td>\n",
       "      <td>-329.691090</td>\n",
       "      <td>-294.990182</td>\n",
       "      <td>-307.125511</td>\n",
       "      <td>15.971450</td>\n",
       "      <td>1</td>\n",
       "      <td>-169.933291</td>\n",
       "      <td>-154.892245</td>\n",
       "      <td>-169.119994</td>\n",
       "      <td>-164.648510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923200</td>\n",
       "      <td>0.019087</td>\n",
       "      <td>0.116019</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 18, 'min_samp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-296.441057</td>\n",
       "      <td>-331.658835</td>\n",
       "      <td>-293.693356</td>\n",
       "      <td>-307.264416</td>\n",
       "      <td>17.285895</td>\n",
       "      <td>1</td>\n",
       "      <td>-170.772067</td>\n",
       "      <td>-155.862307</td>\n",
       "      <td>-168.635799</td>\n",
       "      <td>-165.090058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.054643</td>\n",
       "      <td>0.115691</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>160</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 18, 'min_samp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "18        -293.532209        -331.073780        -296.596204      -307.067398   \n",
       "21        -293.180038        -331.275685        -296.861521      -307.105748   \n",
       "17        -295.642626        -331.898693        -293.793095      -307.111471   \n",
       "15        -296.695262        -329.691090        -294.990182      -307.125511   \n",
       "42        -296.441057        -331.658835        -293.693356      -307.264416   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "18       17.021101                1         -170.098015         -155.302753   \n",
       "21       17.156684                1         -169.861127         -155.325622   \n",
       "17       17.543469                1         -170.790727         -155.990971   \n",
       "15       15.971450                1         -169.933291         -154.892245   \n",
       "42       17.285895                1         -170.772067         -155.862307   \n",
       "\n",
       "    split2_train_score  mean_train_score  ...  mean_fit_time  std_fit_time  \\\n",
       "18         -166.514220       -163.971663  ...       0.778917      0.030326   \n",
       "21         -166.365423       -163.850724  ...       0.751657      0.037015   \n",
       "17         -168.511348       -165.097682  ...       0.767626      0.047225   \n",
       "15         -169.119994       -164.648510  ...       0.923200      0.019087   \n",
       "42         -168.635799       -165.090058  ...       0.679181      0.054643   \n",
       "\n",
       "    mean_score_time  std_score_time  param_max_depth  param_max_features  \\\n",
       "18         0.114030        0.002050                8                  19   \n",
       "21         0.117691        0.002936                8                  19   \n",
       "17         0.113683        0.001421                9                  18   \n",
       "15         0.116019        0.001241                9                  18   \n",
       "42         0.115691        0.004071                9                  18   \n",
       "\n",
       "    param_min_samples_leaf  param_min_samples_split  param_n_estimators  \\\n",
       "18                       2                        3                 151   \n",
       "21                       2                        3                 156   \n",
       "17                       3                        6                 158   \n",
       "15                       3                        6                 200   \n",
       "42                       3                        6                 160   \n",
       "\n",
       "                                               params  \n",
       "18  {'max_depth': 8, 'max_features': 19, 'min_samp...  \n",
       "21  {'max_depth': 8, 'max_features': 19, 'min_samp...  \n",
       "17  {'max_depth': 9, 'max_features': 18, 'min_samp...  \n",
       "15  {'max_depth': 9, 'max_features': 18, 'min_samp...  \n",
       "42  {'max_depth': 9, 'max_features': 18, 'min_samp...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bayes_search.best_estimator_)\n",
    "pd.DataFrame(bayes_search.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regressor Hyperparameter & Pipeline Optimization with `BayesSearchCV` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', PCA(random_state=42, n_components=0.90, svd_solver='full')), \n",
    "                 ('model', XGBRegressor(n_jobs=-1, random_state=42, booster='dart', tree_method='auto'))\n",
    "])\n",
    "\n",
    "search_spaces_xgb = {\n",
    "     'preprocessing':           Categorical([PCA(random_state=42, n_components=0.90, svd_solver='full'), None]),\n",
    "     'model':                   Categorical([XGBRegressor(n_jobs=-1, random_state=42, booster='dart', tree_method='auto')]), \n",
    "     'model__n_estimators':     Integer(50,150),\n",
    "     'model__max_depth':        Integer(4,10),\n",
    "     'model__learning_rate':    Real(0.01,0.6),\n",
    "     'model__gamma':            Real(1.0e-6,1.0e6,'log-uniform'),\n",
    "}\n",
    "#     'model__min_child_weight': Real(0.0,1.0e6),\n",
    "#     'model__max_delta_step':   Real(0.0,1.0e6),\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipe,\n",
    "    search_spaces=search_spaces_xgb,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    scoring='neg_mean_absolute_error',\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('preprocessing', None), ('model', XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=35668.25218114102,\n",
      "       learning_rate=0.03222160693702309, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=nan, n_estimators=149, n_jobs=-1,\n",
      "       nthread=None, objective='reg:linear', random_state=42, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='auto'))])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_preprocessing</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-275.186576</td>\n",
       "      <td>-312.205347</td>\n",
       "      <td>-299.217335</td>\n",
       "      <td>-295.536419</td>\n",
       "      <td>15.335345</td>\n",
       "      <td>1</td>\n",
       "      <td>2.827763</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='dart', c...</td>\n",
       "      <td>35668.252181</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>10</td>\n",
       "      <td>149</td>\n",
       "      <td>None</td>\n",
       "      <td>{'model': XGBRegressor(base_score=0.5, booster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-257.322543</td>\n",
       "      <td>-326.734386</td>\n",
       "      <td>-304.640742</td>\n",
       "      <td>-296.232557</td>\n",
       "      <td>28.954265</td>\n",
       "      <td>1</td>\n",
       "      <td>1.868008</td>\n",
       "      <td>0.019256</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='dart', c...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.078650</td>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>{'model': XGBRegressor(base_score=0.5, booster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-260.080299</td>\n",
       "      <td>-324.124180</td>\n",
       "      <td>-305.784645</td>\n",
       "      <td>-296.663042</td>\n",
       "      <td>26.929630</td>\n",
       "      <td>1</td>\n",
       "      <td>6.129263</td>\n",
       "      <td>0.019548</td>\n",
       "      <td>0.017286</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='dart', c...</td>\n",
       "      <td>21365.998154</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>None</td>\n",
       "      <td>{'model': XGBRegressor(base_score=0.5, booster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-271.723336</td>\n",
       "      <td>-329.234878</td>\n",
       "      <td>-303.181609</td>\n",
       "      <td>-301.379941</td>\n",
       "      <td>23.513526</td>\n",
       "      <td>1</td>\n",
       "      <td>1.213260</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='dart', c...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.083178</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>None</td>\n",
       "      <td>{'model': XGBRegressor(base_score=0.5, booster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-279.438070</td>\n",
       "      <td>-329.838759</td>\n",
       "      <td>-295.143253</td>\n",
       "      <td>-301.473361</td>\n",
       "      <td>21.057224</td>\n",
       "      <td>1</td>\n",
       "      <td>1.525672</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='dart', c...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.036450</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>None</td>\n",
       "      <td>{'model': XGBRegressor(base_score=0.5, booster...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "13        -275.186576        -312.205347        -299.217335      -295.536419   \n",
       "19        -257.322543        -326.734386        -304.640742      -296.232557   \n",
       "12        -260.080299        -324.124180        -305.784645      -296.663042   \n",
       "48        -271.723336        -329.234878        -303.181609      -301.379941   \n",
       "59        -279.438070        -329.838759        -295.143253      -301.473361   \n",
       "\n",
       "    std_test_score  rank_test_score  mean_fit_time  std_fit_time  \\\n",
       "13       15.335345                1       2.827763      0.008711   \n",
       "19       28.954265                1       1.868008      0.019256   \n",
       "12       26.929630                1       6.129263      0.019548   \n",
       "48       23.513526                1       1.213260      0.007363   \n",
       "59       21.057224                1       1.525672      0.007370   \n",
       "\n",
       "    mean_score_time  std_score_time  \\\n",
       "13         0.005318        0.000469   \n",
       "19         0.007313        0.001249   \n",
       "12         0.017286        0.004772   \n",
       "48         0.000000        0.000000   \n",
       "59         0.005209        0.007366   \n",
       "\n",
       "                                          param_model  param_model__gamma  \\\n",
       "13  XGBRegressor(base_score=0.5, booster='dart', c...        35668.252181   \n",
       "19  XGBRegressor(base_score=0.5, booster='dart', c...            0.000001   \n",
       "12  XGBRegressor(base_score=0.5, booster='dart', c...        21365.998154   \n",
       "48  XGBRegressor(base_score=0.5, booster='dart', c...      1000000.000000   \n",
       "59  XGBRegressor(base_score=0.5, booster='dart', c...      1000000.000000   \n",
       "\n",
       "    param_model__learning_rate  param_model__max_depth  \\\n",
       "13                    0.032222                      10   \n",
       "19                    0.078650                      10   \n",
       "12                    0.026171                      10   \n",
       "48                    0.083178                       7   \n",
       "59                    0.036450                       4   \n",
       "\n",
       "    param_model__n_estimators param_preprocessing  \\\n",
       "13                        149                None   \n",
       "19                         53                None   \n",
       "12                        150                None   \n",
       "48                         54                None   \n",
       "59                        136                None   \n",
       "\n",
       "                                               params  \n",
       "13  {'model': XGBRegressor(base_score=0.5, booster...  \n",
       "19  {'model': XGBRegressor(base_score=0.5, booster...  \n",
       "12  {'model': XGBRegressor(base_score=0.5, booster...  \n",
       "48  {'model': XGBRegressor(base_score=0.5, booster...  \n",
       "59  {'model': XGBRegressor(base_score=0.5, booster...  "
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(opt.best_estimator_)\n",
    "pd.DataFrame(opt.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top performing XGBoost model has a  negative mean absolute error of `-295` for the `mean_test_score`, meaning that for a given prediction this model will, on average, be off by 295 cyclists from the true value. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of LS_DS_243_Select_models_and_parameters.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
